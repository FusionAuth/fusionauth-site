---
publish_date: 2025-02-02 
title: Why Mocking Sucks
description: In this article, you'll learn why mocking is a risky practice and how to avoid it.
authors: Matt Keib
categories: Education
tags: single testing mocking
excerpt_separator: "{/* more */}"
---

Developers love mocking. It's been a go-to solution for years: simulate external services, run tests faster, and avoid the overhead of real APIs. But here's the truth—**mocking is overused and often dangerous**. It deceives you into thinking your system is stable, hiding critical failures that only appear when your code hits the real world. APIs change. Rate limits throttle you. Authentication flows break. Your tests will still pass with green colors while your app silently crashes in production.

Mocks can turn your tests into a house of cards, giving you false confidence and creating hidden technical debt that slows teams down. In complex workflows—like payments or authentication—mocks fail to capture the true behavior of interconnected services.

Now, let's pull back the curtain on the dangers of mocking. You'll understand when it works, when it fails miserably, and why relying on mock services can build technical debt faster. With real-world examples like Stripe and Auth0, you'll see how mocking can backfire and why using real dev versions of services often leads to more robust software.

## Why Do You Need to Mock in the First Place?

Mocking solves problems that often arise in modern software development, mainly when dealing with multi-tenant SaaS platforms or distributed systems. If you're working with downloadable or offline software, mocks may not be as critical since your dependencies are within your control. However, mocking can become necessary when your application relies on third-party services—especially APIs you don't own.

Here's why you might need to mock in specific scenarios:
- Testing Failure Scenarios: How do you simulate an API outage or an error response like a 500 Internal Server Error? Mocking lets you control these responses to see how your application behaves under failure conditions.
- Resolve latency issues in tests: External services introduce latency. For example, if you're testing customer registration through an external API, even a 500ms response time can add up across hundreds of tests. Mocking replaces real service calls with near-instant simulated responses, allowing tests to run quickly.
- Simulating External Services that Aren't Ready: Backend APIs or third-party integrations may not be fully available during development in many projects. Mocking helps teams continue their work by simulating those services before they're ready.
    

## When Mocking Works Well: Simple Service Simulations

Mocking works best when simulating simple, isolated services with predictable behavior. For example, mocking is an excellent option if your app integrates with Stripe and you only need to test customer registration. You can simulate a successful customer registration call or even an API failure to verify your error-handling code—all without ever hitting Stripe's servers.

```python
from unittest.mock import patch

@patch('requests.post')
def test_successful_registration(mock_post):
    # Mock the API response
    mock_post.return_value.status_code = 201
    mock_post.return_value.json.return_value = {
        "id": "cus_12345",
        "name": "Test User",
        "email": "test@example.com"
    }

    # Call the function being tested
    result = register_customer("Test User", "test@example.com")

    # Verify the mock behavior and response
    assert result["id"] == "cus_12345"
    assert result["name"] == "Test User"
    assert result["email"] == "test@example.com"
    mock_post.assert_called_once_with(
        "https://api.stripe.com/v1/customers",
        data={"name": "Test User", "email": "test@example.com"}
    )
```

![Simple Stripe Mock](/img/blogs/why-mocking-sucks/simple-stripe-mock.png)

However, this approach completely crumbles when your workflow spans multiple services. Imagine testing a full Stripe payment flow: registering a customer, adding items to a cart, and processing a payment. Mocking each step might seem feasible, but once you combine them, everything falls apart. Inter-service dependencies, timing issues, and API quirks won't surface in your tests.

![Complex Stripe Mock](/img/blogs/why-mocking-sucks/complex-stripe-mock.png)

Your mocks will quietly deceive you, letting you believe your system is stable—until it collapses in production. APIs change without warning, network glitches occur, and mocks won't prepare you for any of it.

This is even more critical for applications that use third-party services for authentication. For example, let's say you are using Auth0 to manage authentication. Mocking here is risky because authentication is mission-critical, and frequent security updates can quickly make your mocks obsolete, breaking your app in production. Worse, authentication failures can shatter user trust, leading to frustration, account lockouts, or even security vulnerabilities.

## When and why mocking sucks

Let's take the stripe example again. Mocking each of these individually is manageable, but maintaining those mocks becomes a nightmare once you simulate the full flow. It requires constant updates to match API changes, introduces inconsistencies, and fails to mimic the nuances of real-world interactions.

Here are the issues:

#### 1\. It Creates a False Sense of Security

Mocks only behave the way you program them to. They'll never catch unexpected changes or errors that might occur with the real service. This gives you the illusion that your system is working perfectly.

Even worse, mocks can accidentally break your product by masking breaking changes. Imagine a situation where a third-party API modifies a key response format. If your mocks aren't updated to reflect this change, your tests will continue to pass while your product silently fails in production. This false confidence leads to missed bugs, broken functionality, and a potentially massive impact on your users and business.

#### 2\. It Increases Maintenance Overhead

APIs evolve. New fields, endpoints, and even minor response tweaks can break your mocks. You'll constantly need to update your test suite to keep up with these changes, which can result in technical debt that burdens your team.

#### 3\. It Encourages Bad Testing Practices

Developers often become complacent with mocks, focusing more on matching expected inputs and outputs than handling real-world edge cases. This leads to over-reliance on happy-path tests that fail to account for errors, latency, or timeouts in real environments.

#### 4\. It Decouples You from Reality

Mocks can't reproduce the unpredictability of real services—rate limiting, version mismatches, or complex state changes in multi-tenant APIs. Tests that never hit real endpoints miss these critical factors, resulting in software unprepared for real-world conditions.

#### 5\. It's an Anti-Pattern for Complex Systems

The more interconnected your services are, the harder it becomes to maintain accurate mocks. In a distributed system, service interactions are dynamic and often undocumented, meaning mocks will never fully reflect actual behavior. Over time, this leads to **tests that become brittle and unreliable**.

### 6\. It Hinders Real Developer Experience

Developers often miss opportunities to work with real APIs early in development due to over-reliance on mocks. This delays the discovery of integration issues, ultimately shifting the pain to later stages, like QA or production.

So what is the solution?

In some cases, you might not have a choice but to mock. When you do, use company-maintained mocks whenever possible—like Stripe's [`stripe-mock`](https://github.com/stripe/stripe-mock), which stays in sync with their API and minimizes maintenance overhead. However, even the best mocks can't replace the benefits of using sandbox or dev environments provided by real services.

You should leverage sandbox APIs for robust systems to run realistic integration tests. But you can't escape latency, rate limits, and downtime even then. These issues can cripple tests and waste time.

## Local-First vs. Mock-Driven Development

This "local-first" development approach aligns with broader trends in modern software engineering. Developers are increasingly favoring real, self-contained environments over artificial mocks. Tools like Docker, Kubernetes, and local microservice setups have empowered teams to replicate production-like conditions at every stage of development. The idea is simple: the more your tests reflect reality, the fewer issues you'll face when deploying to production.

Mocks can still be helpful for specific, isolated tests, but local-first is the future for complex, business-critical systems like authentication.

Here is a table recapitulating the differences between mock-driven development and local-first:

| Category | Mock-Driven Development | Local-First Development |
| --- | --- | --- |
| Maintenance | Requires constant updates to stay in sync with evolving APIs. | Minimal maintenance; stays aligned with production behavior. |
| Reliability | Mocks can mask breaking changes and hidden errors. | Real services expose real-world issues early. |
| Real-World Accuracy | Fails to capture rate limits, network errors, or version mismatches. | Accurately simulates production-like conditions. |
| Developer Experience | Delays integration issue discovery until QA or production. | Developers catch and fix integration issues early in development. |

## Real-world examples of local-first development tools

The trend is clear: it's time to embrace local-first development to provide developers with reliable, production-grade environments they can run locally. By offering real services for development and testing, this approach empowers teams to build with greater confidence and fewer surprises in production.

### Firebase Emulator Suite

Firebase, widely used for authentication, real-time databases, and cloud functions, offers a local emulator suite. The tool allows developers to simulate core Firebase services in their development environment, removing the need for fragile mocks.
- You can test real authentication flows, database queries, and cloud function triggers without depending on the live Firebase servers.
- The emulator provides feature parity with production, allowing reliable integration tests free from rate limits and connectivity issues.

### FusionAuth Kickstart

At FusionAuth, we offer a Quickstart Docker server that provides a real version of our authentication service.

- Developers can spin up a local FusionAuth instance to test full authentication flows, including OAuth and SSO, ensuring tests align with production.
- Our kickstart feature automates environment setup, making maintaining consistent development and CI environments simple. 
- Unlike mocks, this approach handles real-world complexities like security updates and multi-step flows, reducing the risk of surprises in production.

To see how much effective a real dev server can be,  let's write a mock that simulates a [login](/docs/apis/login) on the FusionAuth API. 
    
Here's how you might do it:

```python
import requests
from unittest.mock import patch
import unittest

def fusionauth_login(login_id, password, application_id, base_url="https://sandbox.fusionauth.io"):
    url = f"{base_url}/api/login"
    headers = {"Content-Type": "application/json"}
    data = {
        "loginId": login_id,
        "password": password,
        "applicationId": application_id
    }
    
    response = requests.post(url, json=data, headers=headers)
    
    if response.status_code == 200:
        return {"status": "success", "token": response.json().get("token")}
    elif response.status_code == 404:
        return {"status": "error", "message": "User not found or incorrect password"}
    elif response.status_code == 423:
        return {"status": "error", "message": "User account is locked"}
    else:
        return {"status": "error", "message": "Unknown error"}

class TestFusionAuthLogin(unittest.TestCase):
    
    @patch("requests.post")
    def test_successful_login(self, mock_post):
        mock_post.return_value.status_code = 200
        mock_post.return_value.json.return_value = {
            "token": "fake-jwt-token",
            "user": {"id": "12345", "email": "test@example.com"}
        }

        result = fusionauth_login("test@example.com", "correct-password", "app-123")
        self.assertEqual(result["status"], "success")
        self.assertIn("token", result)
    
    @patch("requests.post")
    def test_invalid_credentials(self, mock_post):
        mock_post.return_value.status_code = 404
        mock_post.return_value.json.return_value = {}

        result = fusionauth_login("test@example.com", "wrong-password", "app-123")
        self.assertEqual(result["status"], "error")
        self.assertEqual(result["message"], "User not found or incorrect password")

    @patch("requests.post")
    def test_locked_account(self, mock_post):
        mock_post.return_value.status_code = 423
        mock_post.return_value.json.return_value = {}

        result = fusionauth_login("locked_user@example.com", "some-password", "app-123")
        self.assertEqual(result["status"], "error")
        self.assertEqual(result["message"], "User account is locked")

    @patch("requests.post")
    def test_unknown_error(self, mock_post):
        mock_post.return_value.status_code = 500
        mock_post.return_value.json.return_value = {}

        result = fusionauth_login("test@example.com", "password", "app-123")
        self.assertEqual(result["status"], "error")
        self.assertEqual(result["message"], "Unknown error")

if __name__ == "__main__":
    unittest.main()
```

The `fusionauth_login` function simulates a login request to FusionAuth's `/api/login` endpoint. It handles various responses—success, incorrect credentials, locked accounts, and unexpected errors. The unit tests use unittest.mock.patch to replace real API calls, ensuring tests pass without needing a live FusionAuth server.

But this approach doesn't scale. For every new scenario, another mock is needed. More tests mean more mocks, more maintenance, and more fragile tests. What starts as a simple test suite quickly turns into a tangled web of artificial responses, each one detached from reality.

And when FusionAuth updates? Your mocks stay frozen in time. New fields, changed response structures, evolving authentication flows—none of it is reflected in your tests. The mocks keep passing, but your application is already broken in production.

Mocks don't capture the real world. They won't expose rate limits, token expirations, network timeouts, or multi-factor authentication failures. They give you an illusion of stability while hiding the cracks until it's too late.
The alternative? Run a real FusionAuth instance locally.

Here's how you can use FusionAuth Kickstart with Docker Compose to test authentication without mocks.

#### Step 1: Download the Docker Compose and Environment Files

Run the following commands to download the required files:

```sh
curl -o docker-compose.yml https://raw.githubusercontent.com/FusionAuth/fusionauth-containers/main/docker/fusionauth/docker-compose.yml
curl -o .env https://raw.githubusercontent.com/FusionAuth/fusionauth-containers/main/docker/fusionauth/.env
```

Edit these files to match your environment. In the `.env` file, you'll want to modify the `DATABASE_PASSWORD` and ensure the `POSTGRES_USER` and `POSTGRES_PASSWORD` are set correctly.

#### Step 2: Start the FusionAuth Containers

Run the following commands to bring up the services:

```sh
docker compose up -d
docker compose logs -f
```

This command starts three services:

1. `db` - A PostgreSQL instance to store your data.
    
2. `search`- An OpenSearch instance for advanced search features.
    
3. `fusionauth` - The main application handling authentication flows.
    

#### Step 3: Explore and Configure FusionAuth

FusionAuth will now be accessible at [`http://localhost:9011`](http://localhost:9011). You can configure your application, manage users, and integrate authentication workflows from here.

The setup uses OpenSearch by default, but you can modify the `docker-compose.yml` file to switch between different search engines if needed.

#### Step 4: Customize for Your Needs

You can further customize the services by editing the `docker-compose.yml` and `.env` files. FusionAuth supports various deployment methods (e.g., Kubernetes, Helm), making it adaptable to different environments. You can learn more about working in a development environment [here](/docs/get-started/download-and-install/development/).

### Step 5: Authenticate a User Using the FusionAuth API

Once FusionAuth is running locally, you can authenticate a user by making a request to the /api/login endpoint. Use the following curl command to test the login flow with real authentication logic:

```bash
curl -X POST http://localhost:9011/api/login \
    -H "Content-Type: application/json" \
    -d '{
        "loginId": "example@fusionauth.io",
        "password": "password",
        "applicationId": "10000000-0000-0002-0000-000000000001"
    }'
```

And running tests in a Dockerized environment has its own set of advantages. For example, a development team is building a microservices-based authentication system. To ensure smooth integration, they initially rely on mocks to simulate FusionAuth responses in their tests.

```python
@patch("requests.post")
def test_successful_login(mock_post):
    mock_post.return_value.status_code = 200
    mock_post.return_value.json.return_value = {
        "token": "fake-jwt-token",
        "user": {"id": "12345", "email": "test@example.com"}
    }
    
    result = fusionauth_login("test@example.com", "correct-password", "app-123")
    
    assert result["status"] == "success"
    assert "token" in result
```

Everything passes in CI. The system is deployed. Then reality sets in.

* Service Discovery Issues: The real FusionAuth service is running inside a Kubernetes cluster, and the application fails to resolve its hostname due to incorrect DNS settings. The mock didn't account for this because it never interacted with the actual service.
* Configuration Drift: In local development, the mock assumed a specific authentication flow. But in production, the real FusionAuth instance required an additional security header, causing unexpected authentication failures.

A simple solution could have prevented this: running FusionAuth inside a Dockerized local environment. Instead of relying on mocks, the team sets up a containerized FusionAuth instance using Docker Compose:

```bash
docker-compose up -d
```

Now, integration tests run against a real authentication service within the same network as the application, replicating production-like conditions. The authentication flow is validated end-to-end, ensuring that DNS resolution, security headers, rate limits, and real response times are properly accounted for—before deployment.


## Final Thoughts: Stop Relying on Mocks

Mocks are risky. They break, they lie, and they hide real-world problems. Complex flows fail, updates blindside you, and tests give you false confidence.

The solution? Use real dev versions of services. Here's why:

- Better Production Alignment - Your tests reflect real-world conditions, including API changes, security updates, and unexpected behavior.
- Lower Maintenance - Say goodbye to constant mock updates. Real services stay consistent with production, reducing technical debt.
- Accurate Testing - Complex workflows like authentication, payments, or multi-step integrations behave correctly, uncovering edge cases early.
- Developer Confidence - With realistic tests, you ship features knowing they'll perform reliably in production.
