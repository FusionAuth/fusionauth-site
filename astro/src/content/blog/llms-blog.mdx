---
publish_date: 2025-06-05 
title: Make Your Devtool Docs Work Smarter with LLMs
description: How can you use LLMs to make your documentation better?
authors: Dan Moore
image: /img/blogs/zero-trust-idps/zero-trust-and-how-idps-factor-into-it-header-image.png
categories: Education
tags: llms, technical documentation, astro, genai
excerpt_separator: "{/* more */}"
---
import {RemoteCode} from '@fusionauth/astro-components';

Large language models (LLMs) are used by more and more developers to discover and use developer tools. In this post, you will learn h how FusionAuth made our docs more accessible to LLMs and developers using them.

{/* more */}

LLMs and LLM enabled tools such as Claude, ChatGPT and Cursor are used by many developers in their daily workflow. In 2024, [a survey from GitHub](https://github.blog/news-insights/research/survey-ai-wave-grows/) found over 97% of the 2000 developers surveyed "used AI coding tools at work at some point".

We also noticed a trend in the last few months. We started getting inbound sales calls from 

Making developers successful with our documentation is something we spend a lot of time on here at FusionAuth. Here are four ways we have modified our docs to make them work better with LLMs, a new tool many developers are using to write software.

Here's a tl;dr table.

| Option | Pros | Cons | Primary Use |
|--------|------|------|------|
| Build great docs | Helps everyone, including developers and search engines     | Large time investment | Discovery, building |
| Chatbot        | Can aggregate across multiple sources of doc, easy buy decision     | Costs money, can be inaccurate     | Discovery |
| Generate LLMs.txt        | Can be auto-updated, emerging standard    | Uncertain effect, development time required, may be big lift depending on where content lives | Building |
| Copy to markdown button        | Lets devs use the LLM of their choosing, leverage LLM for use cases you can't imagine or document     | Development time required, may not be used, UX issues | Building |

The primary use column deserves a bit more exploration. In my experience, there are two ways LLMs can help your company:

* discovery, where an LLM surfaces your tool and helps users discover it--basically a replacement for Google
* building, where an LLM helps a developer build using your tool--basically a replacement for Stack Overflow

These options mostly focus on one of these or the other. Now, let's take a deeper look into each of the options above.

## Build Great Docs

The first and most important way to help developers and LLMs use your docs is to, well, write them. If they don't exist, they won't help anyone.

In addition to writing them, you should:

* structure them well
* include common frequently asked questions
* keep them up to date
* make them fast to download
* generate them where it makes sense
* leverage other tooling to make them consistent
* offer public long tail content (I like to anonymize support tickets and publish them on a forum)

If this seems like boring hard work, that is because it is. Docs are their own product and a key way for your community and prospective developers to evaluate your product with lower risk than downloading or signing up. They're a signal.

This effort pays off though, because in addition to helping LLMs, it also helps SEO (Google is still a massive source of traffic) and developers themselves.

The good folks at Kapa.ai, who provide documentation based LLM chatbots for many companies, including FusionAuth [have a great blog post](https://www.kapa.ai/blog/optimizing-technical-documentation-for-llms) on this topic. So many good pieces of advice in that post, but this one is their top tip: "Embrace Page Structure and Hierarchy". The reason to do so?

> LLMs excel at navigating structured content and rely on context hints to understand the broader picture. A clear hierarchy of headings and subheadings on a page helps LLMs understand the relationships between different sections of your documentation.

The downside of this approach is it takes a lot of effort to build and maintain good documentation.

But if you don't get this right, the rest of the tips are not going to help you out.

### Success Metrics

After building and maintaining docs, you want to make sure they are working for your LLMs for their use cases.

For discovery, ask developers how they found you. We've seen a notable uptick in users mentioning finding FusionAuth via LLMs. In fact, since we started tracking it in our [setup wizard](/docs/get-started/download-and-install/setup-wizard#complete-the-setup-wizard) , it has been one of our top three sources.

TODO image?

For building, you need to understand the questions people are asking in the LLM of their choice. TODO maybe put story's thing in here? The field of analytics around LLM served content is nascent, but you can also manually look for documentation references, unique strings and more.

You can also examine the traffic to your website using your access logs, and see which of your content is being retrieved by the LLM user agents. This is something you'll need access logs to ascertain, since JavaScript tools like Google analytics don't track direct requests to files at a certain location.

While that's not a guarantee that the content is making to users asking questions, it sure doesn't hurt, especially if your content wasn't included in a corpus used to train the LLM.

Here's a sample access log line showing ChatGPT retrieving API documentation.

```
52.255.111.85 - - [01/May/2025:00:17:59 +0000] "GET /docs/apis/two-factor HTTP/2.0" 200 661 "-" "Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko); compatible; ChatGPT-User/1.0; +https://openai.com/bot"
```

While folks talk about LLM scrapers being a major source of traffic, I looked at our logs from Jan 1 - Jun 5 and didn't see it. Here are the percentages of scrapers that identified themselves and made any request resulting in a `200` status code during that timeframe.

| Scraper                     | Percent Of Traffic |
|-----------------------------|--------------------|
| OpenAI                      | 0.99 | 
| Anthropic                   | 0.55 |
| Perplexity                  | 0.18 |
| GoogleBot (used for Gemini) | | 
| BingBog (used for Copilot)  | | 


## Use a Chatbot

Offering up an LLM based chatbot lets you leverage the docs and, importantly, pull in other sources of data. It can be interactive on the docs site and also integrate with other support channels such as Slack, Discord or ticketing systems.

While you can build your own, unless you are an AI focused company wanting to eat your own dogfood, you're probably better off buying this. This is an easy way to exchange money for time.

FusionAuth [installed Kapa.ai's chatbot in 2023](/blog/llm-for-fusionauth-documentation) and have been using it heavily ever since. There are alternatives out there but I haven't seen any as focused on technical documentation. 

We don't just have our techdocs ingested in Kapa, we also ingest our [OpenAPI spec](https://github.com/FusionAuth/fusionauth-openapi), our [YouTube channel](https://www.youtube.com/c/fusionauth), our [forum posts](https://fusionauth.io/community/forum/) and other sources. Kapa has answered tens of thousands of queries, both for external and internal users.

Make sure whatever chatbot you use can say "I don't know" and includes links to source material. We've had minimal hallucinations, but they do happen. Having the source material means that users can verify the answers.

### Success Metrics

The measure of success here is twofold:

* are people using this
* are they finding the answers they need

Both of these metrics should be delivered by any chatbot you use. If you do end up building (don't do it!) make sure you get such reporting.

## LLMs.txt

Another way you can help developers use LLMs to succeed with your docs is to build an `llms.txt` file.

[`llms.txt` is a relatively new standard](https://llms-txt.org/) analogous to the `sitemap.xml` or `robots.txt`, but for LLMs rather than search engine crawlers. The idea is to provide maximum content in minimum number of tokens, so markdown is used rather than HTML. There are actually two files:

* `llms.txt` is a list of URLs with useful content, organized by section. Here's our [docs `llms.txt` file](/docs/llms.txt). 
* `llms-full.txt` is a similar list of content but includes the full text rather than just the URL. Here is our [docs `llms-full.txt` file](/docs/llms-full.txt). 

It's unclear if you can have more than one set of `llms.txt` files for different sections of your site; the standard is still evolving. [Here's an open issue to discuss this](https://github.com/AnswerDotAI/llms-txt/issues/59).

These files file is located at the root of your domain: `https://example.com/llms.txt` for example. This is so LLMs can know where to look for it.

 If you put it somewhere else or have multiple options, make sure to add a link from your HTML pages. Crawlsers for LLMs hunt around but not too much. We shipped an `llms.txt` file for our docs in December in a non-standard location; it was downloaded by the OpenAI chatbot nearly 60 times as much after we linked to it as before.

In addition, when you make them available via a link to your developers, they can upload the file into an LLM or chat console of their choosing to interrogate the docs or learn more about the doc structure.

Make sure these files are automatically updated in the same way your `sitemap.xml` file is so that any new or updated documentation is included.

### Implementation Notes

We did this for our astro docs site using this code for the `llms.txt` file:

<RemoteCode url="https://raw.githubusercontent.com/FusionAuth/fusionauth-site/refs/heads/main/astro/src/pages/docs/llms.txt.ts" lang="javascript" />

You could make it more sophisticated by giving each document in the collection a ranking. For other sections of our website, we handcrafted this file.

For our `llms-full.txt` file, we did something similar: 

<RemoteCode url="https://raw.githubusercontent.com/FusionAuth/fusionauth-site/refs/heads/main/astro/src/pages/docs/llms-full.txt.ts" lang="javascript" />

This pulls in the entire body (`${doc.body}`) rather than just the URL.

We use a lot of includes and I did some work to inline the markdown include files, but that ended up making the `llms-full.txt` file too big for most context windows.

### Success Metrics

See if this is used by how often it is downloaded and by what user agents. Is it being primarily downloaded by LLMs or users? How often? 

This is something you'll need access logs to ascertain, since JavaScript tools like Google analytics don't track direct requests to files at a certain location.

## Add a Copy To Markdown Button

If your tooling supports it, add a copy to markdown button; you can see it below. We've added it to every page of documentation.

![A copy to markdown button on a FusionAuth documentation page.](/img/blogs/llms-for-docs/markdown-button.png)

By offering this, you let developers grab your document, put it into their LLM of choice and transform it to their purpose. It's similar to downloading the `llms-full.txt` file, but uses far fewer tokens. Here are some examples of transformations a developer might do for a technical doc like an API:

* summarize all the error statuses of this API
* explain the key concepts here to me "like I'm 5" or "like I'm an expert software architect" or "like I'm a front end developer"
* how does this API compare with a similar API from \[competitor]
* show me how to use this API in Rust or C++ (or other possibly unsupported languages)
* provide me 10 sets of fake API requests for this API to use in my test harness
* translate this page to Spanish or Swedish

Basically, you don't know exactly what is important to the developer at that moment in time, but they do. And they can ask the LLM to provide it.

Of course someone could copy the HTML and then do the transformation, but that uses more tokens and is more cumbersome.

### Implementation Notes

For our documentation site, we accomplished this using this JavaScript code.

<RemoteCode url="https://raw.githubusercontent.com/FusionAuth/fusionauth-site/refs/heads/main/astro/src/tools/docs/copyMarkdownToClipboard.js" lang="javascript" />

We also used an astro `post:build` plugin.

<RemoteCode url="https://raw.githubusercontent.com/FusionAuth/fusionauth-site/refs/heads/main/astro/src/plugins/markdown-extract.js" lang="javascript" />

This code:

* finds all the document pages 
* inlines all the content in `src/diagrams` and `src/content` (we aren't as worried about overflowing the context window with this single page of markdown)
* removes all the frontmatter
* writes a peer markdown file in a specific location

### Success Metrics

The success metric for this is how many times the copy to markdown button is pressed. Since this is a user driven event, tracking it via a tool like Google Analytics is great.

## Where Is MCP?

The [Model context protocol](https://modelcontextprotocol.io/introduction), or MCP, allows you to let an LLM directly interface with your product. This is something we've explored but not implemented. MCP is great for learning a tool, building protoypes, or debugging. I'm not sure folks will be using it to replace [configuration management](/docs/operate/deploy/configuration-management) in production systems, though.

MCP is not covered here because it is doc-adjacent but not part of documentation. If you have an opinion about the usefulness of a FusionAuth MCP server, well, there's [an open bug for sharing your feedback](https://github.com/FusionAuth/fusionauth-issues/issues/3046). We'd love to hear from you.

## Summing It Up

LLMs are here.

Developers are using them to interact with your documentation.

Use one, two, or all of the options presented above to make it easier for them to do so.
