---
title: Connecting FusionAuth To Twilio Segment
description: Populate your Segment user data with FusionAuth data.
navcategory: admin
section: extend
subcategory: examples
---
import Aside from 'src/components/Aside.astro';
import IconButton from 'src/components/IconButton.astro';
import Breadcrumb from 'src/components/Breadcrumb.astro';
import InlineField from 'src/components/InlineField.astro';
import InlineUIElement from 'src/components/InlineUIElement.astro';


## Introduction

[Twilio Segment](https://segment.com) is an online service that consolidates information about your users from multiple sources. For instance, you might collect purchasing information from your website, interaction patterns from your mobile app, customer feedback through your support channels, and engagement data from email marketing.

This guide shows you how to send FusionAuth data to Segment. Specifically, when a user is created or updated in FusionAuth, they are added to Segment with all their metadata. When the user logs in to FusionAuth, the event is saved in Segment.

<Aside type="caution">
  This guide will not work with FusionAuth Cloud since it uses `localhost` as a location for sending Webhook events. You can use `ngrok` or something similar to proxy to `localhost`, but that is outside the scope of this guide.
</Aside>

## System Design

Running FusionAuth and PostgreSQL in Docker usually looks like the diagram below (you might also run OpenSearch in another Docker container).

![Running FusionAuth architecture](/img/docs/extend/examples/segment/Diagram1.png)

In this guide, you will use [Webhooks](/docs/extend/events-and-webhooks) to send data from FusionAuth to Segment. While Segment stores all the events you send, you can't query Segment's store to extract information. Instead, Segment is intended as a communications hub that receives data from multiple **sources**, filters, adjusts, and merges the data, and sends it to multiple **destinations**. The easiest destination to configure is a PostgreSQL database.

This design looks like the diagram below.

![System design with Segment ](/img/docs/extend/examples/segment/Diagram2.png)

If you already use Segment, you will have your own data warehouse configured, and that's fine. Once you've finished following this guide, using a fresh warehouse for testing, you can add your production warehouse as a destination for the new FusionAuth source.

You're going to follow the steps below in the next sections:

1. Create a free cloud-hosted PostgreSQL database
2. Create a free Segment account and connect the database as a destination and FusionAuth as a source
3. Create a translation service (though his is mis-named Filtering Web Service in the diagram above) that receives FusionAuth Webhooks and translates them to Segment API calls
4. Run FusionAuth, create a new user, and log in with that user to test the whole system

## Create a PostgreSQL Database in Aiven

Since Segment needs a PostgreSQL database that is accessible on the public internet, Aiven is a great option for creating a free publicly accessible database. However, if you already have a server with a public IP address and PostgreSQL installed, you can use that instead.

To set up an Aiven database, follow these steps:

- Browse to https://aiven.io and click <InlineUIElement>Get started for free</InlineUIElement>
- Sign up for a new account and create a new database
- Follow the wizard to the end and wait for the new database instance to start

The screenshot below shows a project called `fa` and a database called `defaultdb`

![Aiven database connection details](/img/docs/extend/examples/segment/segmentAivenDatabase.png)

The Aiven overview page shown above lists all the details you need to create a PostgreSQL connection: host, port, database, username, and password. You can test your connection in a cross-platform database IDE like [DBeaver](https://dbeaver.io/download) or [Azure Data Studio](https://learn.microsoft.com/en-us/azure-data-studio/download-azure-data-studio?tabs=win-install%2Cwin-user-install%2Credhat-install%2Cwindows-uninstall%2Credhat-uninstall#download-azure-data-studio) (ADS). If you use ADS, install the PostgreSQL extension in the sidebar before trying to create a database connection. The details shown in the new connection window below match the ones in the Aiven list above, and will be similar for your database.

![DBeaver](/img/docs/extend/examples/segment/segmentDbeaver.png)

This is all you need for a Segment destination.

## Create a Segment Account

If you don't have a Segment account, register for one:

- Register for a new workspace at https://segment.com/signup.
- Browse to https://app.segment.com.

Add FusionAuth as a source:

- Click <Breadcrumb>Connections -> Sources</Breadcrumb> in the sidebar
- Click <InlineUIElement>Add source</InlineUIElement>
- Choose <InlineUIElement>HTTP API</InlineUIElement> and click <InlineUIElement>Add Source</InlineUIElement> (the Segment API is documented [here](https://segment.com/docs/connections/sources/catalog/libraries/server/http-api))
- Give the source the <InlineField>Name</InlineField> `fa`
- Click <InlineUIElement>Add Source</InlineUIElement>
- Note your <InlineField>Write Key</InlineField>

Add PostgreSQL as a destination:

- Click <Breadcrumb>Connections -> Destinations</Breadcrumb> in the sidebar
- Click <InlineUIElement>Add destination</InlineUIElement>
- Choose <InlineUIElement>Postgres</InlineUIElement>
- Add your connection details from Aiven and test the connection
- Save and continue

![Synchronize warehouse](/img/docs/extend/examples/segment/segmentSyncWarehouse.png)

## Create a Translation Service

<Aside type="note" title="Prequisites">
  You will need Node 22.x or newer to run this example. Use the [Node installation guide](https://nodejs.org/en/download) to install Node if you haven't already
</Aside>

Start by creating a directory for our application called `app`. Then change into this directory and set up a Node project like this:

```shell
mkdir app
cd app
npm init --yes
npm install express
npm install typescript
```

This application will use ESM and Typescript modules, so you'll need to create a file named `tsconfig.json` and add this to it:

```json
{
  "compilerOptions": {
    "allowImportingTsExtensions": true,
    "erasableSyntaxOnly": true,
    "noEmit": true,
    "module": "NodeNext",
    "rewriteRelativeImportExtensions": true,
    "target": "ESNext",
    "verbatimModuleSyntax": true
  }
}
```

And finally, open the `package.json` file and add this attribute to the top level:

```json
"type": "module",
```

This will ensure that Typescript and Node correctly execute the code below.

Next, create a file called `translation.mts` and copy the code below into it. You'll need to change the `_writeKey` constant to contain your Segment key.

```ts
import express, {type Application} from 'express';
import https from 'https';

const app: Application = express();

app.use(express.json());

const _writeKey = '<YOUR-KEY>';
const _apiUrl = 'https://api.segment.io';

app.post('/', (req, res) => {
  console.log(`FusionAuth segment translation -> received a ${req.body.event.type} event`);

  try {
    switch (req.body.event.type) {
      case 'user.create.complete':
      case 'user.update.complete':
      case 'user.email.update':
        callSegmentIdentify(req.body);
        break;
      case 'user.login.success':
        callSegmentTrack(req.body);
        break;
    }

    res.status(200).send('OK');
  } catch (e) {
    res.status(500).send('Internal server error');
  }
});

app.listen(8080, '0.0.0.0', () => {
  console.log('Server running on port 8080');
});

function convertToDate(timestamp: string) {
  return timestamp ? new Date(timestamp).toISOString() : '';
}

function callSegmentIdentify(body) {
  const data = {
    'writeKey': _writeKey,
    'event': body.event.type,
    'userId': body.event.user.id,
    'timestamp': convertToDate(body.event.createInstant),
    'context': {
      'ip': body.event.ipAddress,
      'deviceName': body.event.info.deviceName,
      'deviceType': body.event.info.deviceType,
      'userAgent': body.event.info.userAgent,
    },
    'traits': {
      'data': body.event.data,
      'email': body.event.user.email,
      'firstName': body.event.user.firstName,
      'lastName': body.event.user.lastName,
      'active': body.event.user.active,
      'birthDate': body.event.user.birthDate,
      'connectorId': body.event.user.connectorId,
      'insertInstant': body.event.user.insertInstant,
      'lastLoginInstant': body.event.user.lastLoginInstant,
      'lastUpdateInstant': body.event.user.lastUpdateInstant,
      'memberships': body.event.memberships,
      'passwordChangeRequired': body.event.user.passwordChangeRequired,
      'passwordLastUpdateInstant': body.event.user.passwordLastUpdateInstant,
      'preferredLanguages': body.event.preferredLanguages,
      'registrations': body.event.registrations,
      'tenantId': body.event.user.tenantId,
      'twoFactor': body.event.twoFactor,
      'usernameStatus': body.event.user.usernameStatus,
      'verified': body.event.user.verified,
      'verifiedInstant': body.event.user.verifiedInstant
    }
  };

  const req = https.request(`${_apiUrl}/v1/identify`,
      {method: 'POST', headers: {'Content-Type': 'application/json'}});
  req.write(JSON.stringify(data));
  req.end();
}

function callSegmentTrack(body) {
  const data = {
    'writeKey': _writeKey,
    'event': body.event.type,
    'userId': body.event.user.id,
    'timestamp': convertToDate(body.createInstant),
    'properties': { /* none yet */},
    'context': {
      'ip': body.event.ipAddress,
      'deviceName': body.event.info.deviceName,
      'deviceType': body.event.info.deviceType,
      'userAgent': body.event.info.userAgent,
      'applicationId': body.event.applicationId,
    }
  };

  const req = https.request(`${_apiUrl}/v1/identify`,
      {method: 'POST', headers: {'Content-Type': 'application/json'}});
  req.write(JSON.stringify(data));
  req.end();
}
```

The Segment API endpoint URL might differ depending on whether you created your workspace in the USA or EU. Either https://events.eu1.segmentapis.com or https://api.segment.io.

The code above has three important operations:

1. It consumes incoming FusionAuth Webhook events in the Express route for `/`
2. It translates these into Segment API calls to either `identify` an object or `track` an object
3. The `identify` operation converts a FusionAuth user to a set of Segment traits and the `track` operation converts the FusionAuth event to a Segment event

<Aside type="caution">
The Segment API [returns a successful status code for most errors](https://segment.com/docs/connections/sources/catalog/libraries/server/http-api/#errors). Check the debugger log on the Segment website if your data does not show in the Segment events list.
</Aside>

Now that our translation application is ready to go, run this command to start the Node server:

```shell
node --watch --experimental-strip-types translation.mts
```
### Install FusionAuth

If you haven't already installed FusionAuth, you should follow the instructions on our [Download](/download) page or you can follow the process in our [Getting Started](/docs/get-started/start-here/step-1) guide.

If you already have FusionAuth running locally or are using FusionAuth Cloud, you are welcome to use that instance as well.

## Configure FusionAuth

Now that Segment is prepared and you have a service to send events, you need to configure FusionAuth to send Webhook events to the translation service. To accomplish this, follow these steps:

- Browse to http://localhost:9011/admin and log in with the admin user
- In the FusionAuth web interface, browse to Tenants
- Edit the default tenant
- Click the <Breadcrumb>Webhooks</Breadcrumb> tab
- Enable Webhooks for the events:
  - [x] user.create.complete
  - [x] user.email.update
  - [x] user.login.success
  - [x] user.update.complete
- Click <IconButton icon="save" color="blue"/> at the top right of the page
- Browse to <Breadcrumb>Settings -> Webhooks</Breadcrumb>
- Click <IconButton icon="add" color="green"/> at the top right
- Enter the URL `http://localhost:8080` (if you running FusionAuth in Docker use `http://host.docker.internal:8080` instead)
- Click <IconButton icon="save" color="blue"/> at the top right

You can click Test on the created Webhook now to see example JSON for all the events that will be sent.

## Test The System

Now that everything is running and configured, let's test our Segment integration. To test the `track` event in Segment, log out of the FusionAuth admin and log back in. In the terminal, you should see a notification from the translation service that looks like this:

```sh
FusionAuth segment translation -> received a user.login.success event
```

In Segment, you should see your event arriving. You may have to refresh the page. If you cannot see your event, you my need to consult the Segment documentation or contact Twilio for assistance.

![Segment event debugger](/img/docs/extend/examples/segment/segmentEventReceived.png)

You should also be able to refresh your database view and see that data has arrived in the destination table. The new event might not propagate to PostgreSQL until the Segment store is synchronized with the warehouse in a few hours. In some cases, Segmnet won't send events to the PostgreSQL database, which might require some additional configuration to order to work properly. That configuration is outside of the scope of this guide, but consult the Segment documentation for assistance.

To test the `identify` event, let's create a new user. Browse to http://localhost:9011/admin/user and create a new user.

![New FusionAuth user](/img/docs/extend/examples/segment/segmentNewUser.png)

In the terminal, you should see a notification from the filtering script:

```sh
FusionAuth segment translation -> received a user.create.complete event
```

The event should show in the Segment event list as an `identify` type.

## Next Steps

Now that your FusionAuth user data is available in your data warehouse, you can write a SQL query on user Id or email address to match user data in FusionAuth to user activity sent to Segment from your other apps.

At this stage, you might want to:
- Add more event types to the translation service
- Change the user data sent to Segment (being mindful of your users' data privacy)
- Forward the data to your real destinations instead of the test PostgreSQL instance

